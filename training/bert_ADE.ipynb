{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e77a071d-a40d-4431-ad39-93f3ec68eabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BERT AUTOMATIC DEFINITION EXTRACTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1c76697-5f9c-4f53-9d04-6ba0ea47b906",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers -q\n",
    "!pip install tqdm -q\n",
    "!pip install scikit-learn -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78694070-8f11-4bdd-8799-01df0d262fa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/python/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizer, BertModel\n",
    "#from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import pandas as pd\n",
    "from torch.optim import AdamW\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97141696-c697-491f-b797-f360687050a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/python/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "100%|██████████| 1092/1092 [03:14<00:00,  5.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1] Training Loss: 0.3932, Train Acc: 0.8264, Val Loss: 0.2934, Val Acc: 0.8841\n",
      "new best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1092/1092 [03:17<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2] Training Loss: 0.2778, Train Acc: 0.8879, Val Loss: 0.3012, Val Acc: 0.8817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1092/1092 [03:16<00:00,  5.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 3] Training Loss: 0.2044, Train Acc: 0.9207, Val Loss: 0.3254, Val Acc: 0.8852\n",
      "Early stopping.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.8683    0.9207    0.8937       580\n",
      "         1.0     0.8115    0.7097    0.7572       279\n",
      "\n",
      "    accuracy                         0.8522       859\n",
      "   macro avg     0.8399    0.8152    0.8254       859\n",
      "weighted avg     0.8498    0.8522    0.8494       859\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# ----- 6. Evaluation Function -----\n",
    "def evaluate(loader, return_loss=False):\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch, labels in loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(input_ids, attention_mask)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            preds = (outputs > 0.5).int().cpu().numpy()\n",
    "            all_preds.extend(preds)\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    if return_loss:\n",
    "        return acc, total_loss / len(loader)\n",
    "    else:\n",
    "        return acc\n",
    "\n",
    "# === final classification report evaluation ===\n",
    "def predict_all(loader):\n",
    "    model.eval()\n",
    "    preds, targets = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch, labels in loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "\n",
    "            output = model(input_ids, attention_mask)\n",
    "            preds.extend((output > 0.5).int().cpu().numpy())\n",
    "            targets.extend(labels.numpy())\n",
    "\n",
    "    return targets, preds\n",
    "\n",
    "# ----- Load Data -----\n",
    "datapath = \"./data/\"\n",
    "\n",
    "train_df = pd.read_csv(datapath+\"task1_train.csv\")\n",
    "dev_df = pd.read_csv(datapath+\"task1_dev.csv\")\n",
    "test_df = pd.read_csv(datapath+\"task1_test_labeled.csv\")\n",
    "\n",
    "# ----- 2. Dataset Class -----\n",
    "class SentenceDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer, max_len=64):\n",
    "        self.encodings = tokenizer(df[\"Sentence\"].tolist(), truncation=True, padding=True,\n",
    "                                   max_length=max_len, return_tensors=\"pt\")\n",
    "        self.labels = torch.tensor(df[\"Label\"].tolist()).float()\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {key: val[idx] for key, val in self.encodings.items()}, self.labels[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "# ----- 3. Model -----\n",
    "class BERTClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.bert = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "        self.fc = nn.Linear(self.bert.config.hidden_size, 1)  # Binary classification\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        out = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        cls = out.pooler_output\n",
    "        return torch.sigmoid(self.fc(cls)).squeeze()\n",
    "\n",
    "# ----- 4. Setup -----\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "train_data = SentenceDataset(train_df, tokenizer)\n",
    "dev_data   = SentenceDataset(dev_df, tokenizer)\n",
    "test_data  = SentenceDataset(test_df, tokenizer)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=16, shuffle=True)\n",
    "dev_loader   = DataLoader(dev_data, batch_size=16)\n",
    "test_loader  = DataLoader(test_data, batch_size=16)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = BERTClassifier().to(device)\n",
    "optimizer = AdamW(model.parameters(), lr=1e-5, weight_decay=0.01)\n",
    "loss_fn = nn.BCELoss()\n",
    "\n",
    "# ----- 5. Training -----\n",
    "best_val_loss = float('inf')\n",
    "patience = 2\n",
    "patience_counter = 0\n",
    "epochs = 5\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    \n",
    "    for batch, labels in tqdm(train_loader) :\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(input_ids, attention_mask)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Collect predictions and labels for accuracy\n",
    "        preds = (outputs > 0.5).int().cpu().numpy()\n",
    "        all_preds.extend(preds)\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    # Compute training accuracy\n",
    "    train_acc = accuracy_score(all_labels, all_preds)\n",
    "\n",
    "    val_acc, val_loss = evaluate(dev_loader, return_loss=True)\n",
    "    print(f\"[Epoch {epoch+1}] Training Loss: {total_loss / len(train_loader):.4f}, Train Acc: {train_acc:.4f}, \"\n",
    "          f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "    \n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        patience_counter = 0\n",
    "        torch.save(model.state_dict(), \"best_model3.pt\")\n",
    "        print(\"new best model\")\n",
    "\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= patience:\n",
    "            print(\"Early stopping.\")\n",
    "            break\n",
    "\n",
    "    # Compute training accuracy\n",
    "    train_acc = accuracy_score(all_labels, all_preds)\n",
    "\n",
    "    '''val_acc, val_loss = evaluate(dev_loader, return_loss=True)\n",
    "    print(f\"[Epoch {epoch+1}] Training Loss: {total_loss / len(train_loader):.4f}, Train Acc: {train_acc:.4f}, \"\n",
    "          f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")'''\n",
    "\n",
    "\n",
    "# ----- 7. Run Eval -----\n",
    "model.load_state_dict(torch.load(\"best_model3.pt\"))\n",
    "\n",
    "y_true, y_pred = predict_all(test_loader)\n",
    "print(classification_report(y_true, y_pred, digits=4))\n",
    "\n",
    "\n",
    "#print(\"Dev Accuracy:\", predict_all(dev_loader))\n",
    "#print(\"Test Accuracy:\", evaluate(test_loader)) #No label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "745b1603-f804-4f32-9ebf-2e786b43eabb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9033    0.8862    0.8947       580\n",
      "         1.0     0.7724    0.8029    0.7873       279\n",
      "\n",
      "    accuracy                         0.8591       859\n",
      "   macro avg     0.8379    0.8445    0.8410       859\n",
      "weighted avg     0.8608    0.8591    0.8598       859\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ----- 7. Run Eval -----\n",
    "model.load_state_dict(torch.load(\"best_model2.pt\"))\n",
    "\n",
    "y_true, y_pred = predict_all(test_loader)\n",
    "print(classification_report(y_true, y_pred, digits=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ccde998-aa55-4b6d-b5ef-ea1bb68517fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9120    0.8759    0.8936       580\n",
      "         1.0     0.7616    0.8244    0.7917       279\n",
      "\n",
      "    accuracy                         0.8591       859\n",
      "   macro avg     0.8368    0.8501    0.8427       859\n",
      "weighted avg     0.8632    0.8591    0.8605       859\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ----- 7. Run Eval -----\n",
    "model.load_state_dict(torch.load(\"best_model.pt\"))\n",
    "\n",
    "y_true, y_pred = predict_all(test_loader)\n",
    "print(classification_report(y_true, y_pred, digits=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1116a6f8-4288-4777-a3d2-59c388434453",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'model.save_pretrained(\"bert_best_mod\")\\ntokenizer.save_pretrained(\"bert_best_tok\")'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save after training\n",
    "'''model.save_pretrained(\"bert_best_mod\")\n",
    "tokenizer.save_pretrained(\"bert_best_tok\")'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ec4ff5-b427-4787-b880-9a3114f6a004",
   "metadata": {},
   "source": [
    "### INference Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c60130e2-aff8-4aaa-a68a-f5eae49b2c43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model loaded\n"
     ]
    }
   ],
   "source": [
    "# Load model for inference / Prod\n",
    "\n",
    "from transformers import BertForSequenceClassification, BertTokenizer\n",
    "import torch\n",
    "\n",
    "# ----- 3. Model -----\n",
    "class BERTClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.bert = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "        self.fc = nn.Linear(self.bert.config.hidden_size, 1)  # Binary classification\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        out = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        cls = out.pooler_output\n",
    "        return torch.sigmoid(self.fc(cls)).squeeze()\n",
    "\n",
    "# ----- 4. Setup -----\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = BERTClassifier().to(device)\n",
    "model.load_state_dict(torch.load(\"best_model.pt\"))\n",
    "model.eval()\n",
    "print(\"model loaded\")\n",
    "\n",
    "#Predict function\n",
    "def predict_sentences(sentences, model, tokenizer, device):\n",
    "    model.eval()\n",
    "    encodings = tokenizer(sentences, padding=True, truncation=True, return_tensors=\"pt\").to(device)\n",
    "    encodings.pop(\"token_type_ids\", None)  # Optional if forward doesn't take it\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        probs = model(**encodings)  # Already sigmoid outputs from your forward\n",
    "        preds = (probs >= 0.5).long()  # Threshold for binary classification\n",
    "    \n",
    "    return preds.cpu().numpy(), probs.cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a2c6dae6-720b-4502-b97f-cf469a5c1b45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0]\n",
      "[0.939231   0.00966283]\n"
     ]
    }
   ],
   "source": [
    "texts = [\n",
    "    \"The atom is the smallest unit of matter.\",\n",
    "    \"I hate rainy days.\"\n",
    "]\n",
    "pred_labels, pred_probs = predict_sentences(texts, model, tokenizer, device)\n",
    "print(pred_labels)  # e.g. [1, 0]\n",
    "print(pred_probs)   # e.g. [[0.1, 0.9], [0.8, 0.2]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dbf522c-159e-4581-893f-ecebc8c00825",
   "metadata": {},
   "source": [
    "#### BATCHED VERSION OF PREDICTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04d9e6ee-ad8c-4acd-936f-da12ab514bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# ------------------------------\n",
    "# Dataset for inference\n",
    "# ------------------------------\n",
    "class SentenceTermDataset(Dataset):\n",
    "    def __init__(self, sentences, terms, tokenizer, max_length=128):\n",
    "        self.sentences = sentences\n",
    "        self.terms = terms\n",
    "        self.encodings = tokenizer(\n",
    "            sentences,\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            max_length=max_length,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.sentences)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
    "        item[\"term\"] = self.terms[idx]\n",
    "        item[\"sentence\"] = self.sentences[idx]\n",
    "        return item\n",
    "\n",
    "# ------------------------------\n",
    "# Batched prediction\n",
    "# ------------------------------\n",
    "def predict_in_batches(sentences, terms, model, tokenizer, device, batch_size=32):\n",
    "    dataset = SentenceTermDataset(sentences, terms, tokenizer)\n",
    "    loader = DataLoader(dataset, batch_size=batch_size)\n",
    "\n",
    "    model.eval()\n",
    "    all_terms, all_sentences, all_preds, all_probs = [], [], [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(loader):\n",
    "            # Extract fields\n",
    "            term_batch = batch.pop(\"term\")\n",
    "            sentence_batch = batch.pop(\"sentence\")\n",
    "            \n",
    "            # Send tensors to device\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            batch.pop(\"token_type_ids\", None)  # Optional if model.forward doesn't take it\n",
    "\n",
    "            # Forward pass\n",
    "            probs = model(**batch)  # Already sigmoid outputs from your forward\n",
    "            preds = (probs >= 0.5).long()\n",
    "\n",
    "            # Store\n",
    "            all_terms.extend(term_batch)\n",
    "            all_sentences.extend(sentence_batch)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "\n",
    "    return all_terms, all_sentences, all_preds, all_probs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb1834f4-dc6c-4a15-b361-f626c0a0a4fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:01<00:00,  7.54it/s]\n"
     ]
    }
   ],
   "source": [
    "matches = pd.read_csv(\"data/deft_matches.csv\")\n",
    "sentences = matches[\"sentence\"].to_list()\n",
    "terms = matches[\"terms\"].to_list()\n",
    "\n",
    "\n",
    "terms_out, sentences_out, preds, probs = predict_in_batches(\n",
    "    sentences, terms, model, tokenizer, device, batch_size=16\n",
    ")\n",
    "\n",
    "# Save to CSV\n",
    "df = pd.DataFrame({\n",
    "    \"term\": terms_out,\n",
    "    \"sentence\": sentences_out,\n",
    "    \"pred_label\": preds,\n",
    "    \"pred_prob\": [float(p) for p in probs]\n",
    "})\n",
    "df.to_csv(\"predictions.csv\", index=False, sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae02154c-ba49-4046-9df1-c40c1a99feb2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
